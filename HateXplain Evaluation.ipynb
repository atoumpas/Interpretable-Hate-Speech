{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oAplQ_Yp8G_Y"
   },
   "source": [
    "# Preliminary procedures\n",
    "\n",
    "First, we import the Transformer, Ethos, and HateXplain libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U4hdzhu872cU",
    "outputId": "92bd7c62-e3de-4bc5-e4ed-77612341559d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####################################################################\n",
      "#                           HateXplain                              #\n",
      "#####################################################################\n",
      "#                    (distil)BERT Evaluation                        #\n",
      "#####################################################################\n"
     ]
    }
   ],
   "source": [
    "print('#####################################################################')\n",
    "print('#                           HateXplain                              #')\n",
    "print('#####################################################################')\n",
    "print('#                    (distil)BERT Evaluation                        #')\n",
    "print('#####################################################################')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qknYpVYmtBsD",
    "outputId": "a963f3f9-fead-490e-886c-198f81798750"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.15.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.10.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.47)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "# First we are going to install the transformers library by hugging face!\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "! pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MiYRKXBht0-C",
    "outputId": "aa59308b-99a7-4766-aa20-98d520b56bc5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'HateXplain' already exists and is not an empty directory.\n",
      "mv: cannot stat '/content/HateXplain/Data': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "#Clone the HateXplain dataset\n",
    "!git clone https://github.com/hate-alert/HateXplain/\n",
    "!mv '/content/HateXplain/Data' '/content/Data'\n",
    "\n",
    "#Choose between Bert and DistilBert\n",
    "model_used = 'Bert'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L2RDC9Aw6u0i"
   },
   "source": [
    "# Prepare HateXplain Dataset\n",
    "\n",
    "We now load the HateXplain dataset. We extract the samples that are labeled 'hate speech' or 'normal', preprocess the respective text, and create the ground truth vector.\n",
    "\n",
    "We then split the samples into two datasets, train and test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145,
     "referenced_widgets": [
      "bd2a3b1ae6294123b9bedf3f54e21817",
      "c9883f3149e44674b38cb5702c20f9ac",
      "9fea71a96a19486cb174bf6efc3c836e",
      "8d6020b7d5574a559af636b82b72ba6e",
      "571ebcb725c1411d97e087d93a63e1b2",
      "112051f8f4144c12a84d30ac1037b394",
      "9d115699d3124cf293c97a3b041327e0",
      "07d772f2e9274368bfc6c4ceca5d1fa3",
      "8a1b581289bc494c8eb6c43160779993",
      "67c43adb9c724781a0b3dda6eec8151e",
      "efc2b0c4bbc04c12b5881d047ebced5d",
      "d676303de9fb4c528a178031afcbb4de",
      "42519b4bd04d49ef92ce30e72d4c798f",
      "70fda8df889c4155a1ce749fb31cf067",
      "a3dbe12b767d4203b703cc1c4b15024f",
      "21c88403bea94e088495fad3cc92d344",
      "d3f17de082f54c42823ff7a82076ff6a",
      "cc746aa48ee243159c766a8fc0b00e8d",
      "1e79b09b5d684e3a8dc288cb65f87679",
      "a3f886dbd6c24292bd38d31e5954f11f",
      "081ea3173d754ab0a0e608bea79b7254",
      "bc2e2eefc59846278f3c59478bb74ebb",
      "202e1116a5de48e59c61022fc7a78e8e",
      "c3f0caf43cf84fa4ad308f413c53a4b6",
      "7cf13684d5044c0c945854a912049799",
      "5843af756e3c42689d2c34d2abc91e07",
      "cdcffb5e6b3c4db7a8a425fbf510ca5f",
      "53a3247730424b7394c906269b9000f2",
      "92ad4986898e43bca22787e94d34deac",
      "d089ba5080784d4199af642031386700",
      "a1a9debac2644c4f88456da2c97d6e7e",
      "a68f54b7107c49408b8b391b4b824cac",
      "ff2a95e5455744f3b7f6d082788bdf03",
      "96b49575251948eb862dffb96266a0eb",
      "fcdba66e4a7748f982e677ac222d98fc",
      "2de454f08ef34be390d82656600abf3a",
      "8fe218c1b6d8433b8dee577d8c430998",
      "8e26e633273a4fafa1ef90b0f8831c1a",
      "b4935b7c13ee4759a56794030e76646a",
      "1039074a09fd4549b48d6824f2216cdd",
      "d61b5b8630524d3a8a7f19f2cceb59de",
      "ffe2859dba7e4dcabea2ece56947d094",
      "35cbf5c213574362b3e05889e30be477",
      "346dbcafd2634e4d87b615c4835e9ef0"
     ]
    },
    "id": "ogdcEsH1tBsT",
    "outputId": "ec716c84-2199-48cc-8388-d3c723e559c0"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd2a3b1ae6294123b9bedf3f54e21817",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d676303de9fb4c528a178031afcbb4de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "202e1116a5de48e59c61022fc7a78e8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96b49575251948eb862dffb96266a0eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from scipy.special import softmax\n",
    "\n",
    "if model_used == 'Bert':\n",
    "    from transformers import BertTokenizerFast\n",
    "    from transformers import BertForSequenceClassification, Trainer, TrainingArguments\n",
    "    tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "else:\n",
    "    from transformers import DistilBertTokenizerFast \n",
    "    from transformers import DistilBertForSequenceClassification, Trainer, TrainingArguments \n",
    "    tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "\n",
    "#Preprocess text tokens by removing <> and replacing all numbers with 'number'\n",
    "def preprocess(tokens):\n",
    "    for i in range(len(tokens)):\n",
    "        tokens[i] = re.sub(r\"[<\\*>]\", \"\",tokens[i])\n",
    "        tokens[i] = re.sub(r\"\\b\\d+\\b\", \"number\", tokens[i])\n",
    "    return tokens\n",
    "\n",
    "\n",
    "#Function to extract ground truth attention vector from the annotator rationales\n",
    "def getGroundTruth(key, tokens):\n",
    "    original_rationales = data[key]['rationales']\n",
    "    new_rationales = []\n",
    "\n",
    "    #Calculate the BERT token splits\n",
    "    lengths = []\n",
    "    for token in tokens:\n",
    "        lengths.append(len(tokenizer.tokenize(token)))\n",
    "\n",
    "    #Adjust each rationale to the new BERT tokens\n",
    "    for current_rationale in original_rationales:\n",
    "        tweaked_rationale = []\n",
    "        for weight, length in zip(current_rationale, lengths):\n",
    "            tweaked_rationale += length * [weight]\n",
    "        new_rationales.append(tweaked_rationale)\n",
    "\n",
    "    #Produce final rationale vector through union of the annotator rationales\n",
    "    ground_truth = [int(any(weight)) for weight in zip(*new_rationales)]\n",
    "    return ground_truth\n",
    "\n",
    "#Load HateXplain dataset\n",
    "with open('Data/dataset.json', 'r') as fp:\n",
    "    data = json.load(fp)\n",
    "\n",
    "X = []\n",
    "y = [] \n",
    "ground_truth = []\n",
    "\n",
    "#For each sample\n",
    "for key in data:\n",
    "    #Construct the string                                          \n",
    "    tokens = data[key]['post_tokens']\n",
    "    tokens = preprocess(tokens)\n",
    "    text = ' '.join(tokens)  \n",
    "\n",
    "    #Get all 3 labels of annotators\n",
    "    annotator_labels = []\n",
    "    for i in range(3):                                    \n",
    "        annotator_labels.append(data[key]['annotators'][i]['label'])\n",
    "  \n",
    "    #Get final label based on majority voting\n",
    "    final_label=max(annotator_labels,key=annotator_labels.count)\n",
    "\n",
    "    #If label was either \"hate speech\" or \"normal speech\", preprocess string, create ground truth vector and add the sample to the list\n",
    "    if(annotator_labels.count(final_label)!=1):\n",
    "        if(final_label == 'hatespeech'):\n",
    "            X.append(text)\n",
    "            y.append(int(1))\n",
    "            ground_truth.append(getGroundTruth(key, tokens))\n",
    "        elif(final_label == 'normal'):\n",
    "            X.append(text)\n",
    "            y.append(int(0))\n",
    "            ground_truth.append(int(0)) #We are not going to use these ground truths\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "class_names = ['noHateSpeech', 'hateSpeech']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QKHTWyiyLQQ8",
    "outputId": "60f86fa7-fef0-4639-d67e-7849b8c356e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total amount: 13749\n",
      "Hate speech: 5935\n",
      "Non Hate speech: 7814\n",
      "\n",
      "Example sample\n",
      "user i am bit confused coz chinese ppl can not access twitter thn how this ching chong using it i think he pakistani ðŸ¤” ðŸ¤” ðŸ¤”\n",
      "1\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(\"Total amount:\",len(y))\n",
    "print(\"Hate speech:\",sum(y))\n",
    "print(\"Non Hate speech:\",len(y)-sum(y))\n",
    "print()\n",
    "print(\"Example sample\")\n",
    "print(X[3])\n",
    "print(y[3])\n",
    "print(ground_truth[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u7iK93gNfcPT",
    "outputId": "011085ad-49c8-45e8-ae39-dbeec925beda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples:  9624\n",
      "Validation samples:  1375\n",
      "Test samples:  2750\n"
     ]
    }
   ],
   "source": [
    "#Split dataset into train, validation, and test (70% - 10% - 20%)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "indices = np.arange(len(y))\n",
    "train_texts, test_texts, train_labels, test_labels, _, test_indexes = train_test_split(list(X), y, indices, stratify=y, test_size=.2, random_state=42)\n",
    "#Keep ground truth for test samples only\n",
    "ground_truth = [ground_truth[x] for x in test_indexes]\n",
    "\n",
    "size = (0.1 * len(y)) / len(train_labels)\n",
    "train_texts, validation_texts, train_labels, validation_labels = train_test_split(list(train_texts), train_labels, stratify=train_labels, test_size=size, random_state=42)\n",
    "\n",
    "print(\"Training samples: \",len(train_labels))\n",
    "print(\"Validation samples: \",len(validation_labels))\n",
    "print(\"Test samples: \",len(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8K7ZJYK5Z6VE",
    "outputId": "763f3624-add2-47b1-8a25-42c142f9c35b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 1, 1, 1, 1, 1]\n",
      "[(2, 7)]\n",
      "Ground truth average:  0.4442347618299537\n"
     ]
    }
   ],
   "source": [
    "#Construct hard ground truth\n",
    "import more_itertools as mit\n",
    "\n",
    "#Return start and end index of each hard rationale\n",
    "def find_rationale_range(iterable):\n",
    "    \"\"\"Yield range of consecutive numbers.\"\"\"\n",
    "    for group in mit.consecutive_groups(iterable):\n",
    "        group = list(group)\n",
    "        if len(group) == 1:\n",
    "            yield (group[0], group[0] + 1)\n",
    "        else:\n",
    "            yield (group[0], group[-1] + 1) \n",
    "\n",
    "def extract_hard_truth(ground_truth):\n",
    "    hard_truth = []\n",
    "    for rationale in ground_truth:\n",
    "        if rationale == 0:\n",
    "            hard_truth.append(0)\n",
    "        else:\n",
    "            rationale_indexes = [index for index, weight in enumerate(rationale) if weight==1]\n",
    "            hard_truth.append(list(find_rationale_range(rationale_indexes)))\n",
    "    return hard_truth\n",
    "\n",
    "hard_truth = extract_hard_truth(ground_truth)\n",
    "print(ground_truth[3])\n",
    "print(hard_truth[3])\n",
    "\n",
    "#Calculate ground truth average across hate speech samples\n",
    "avg_per_sample = []\n",
    "for truth in ground_truth:\n",
    "    if truth != 0:\n",
    "        avg_per_sample.append(np.average(truth))\n",
    "ground_truth_avg = np.average(avg_per_sample)\n",
    "print(\"Ground truth average: \",ground_truth_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V7VDGeDKtBsU"
   },
   "source": [
    "# Prepare (Distil)Bert\n",
    "\n",
    "We create the train and test datasets using the (Distil)Bert tokenizer, and set the training parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZZgilnQrNrlL"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "#Set training arguments\n",
    "training_args = TrainingArguments(\n",
    "    evaluation_strategy='epoch',     # evaluation frequency\n",
    "    save_strategy='epoch',           # model checkpoint frequency\n",
    "    logging_strategy='epoch',        # logging frequency\n",
    "    log_level='warning',             # logging level\n",
    "    output_dir='./results',          # output directory\n",
    "    num_train_epochs=6,              # total number of training epochs\n",
    "    per_device_train_batch_size=4,   # batch size per device during training\n",
    "    per_device_eval_batch_size=32,   # batch size for evaluation\n",
    "    warmup_steps=200,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.001,              # strength of weight decay\n",
    "    logging_dir='./logs'             # directory for storing logs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_4Dxbkwg9VeV"
   },
   "outputs": [],
   "source": [
    "#Create the train and test datasets\n",
    "class HateSpeechDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_encodings = tokenizer(list(train_texts), truncation=True, padding=True)\n",
    "validation_encodings = tokenizer(list(validation_texts), truncation=True, padding=True)\n",
    "test_encodings = tokenizer(list(test_texts), truncation=True, padding=True)\n",
    "    \n",
    "train_dataset = HateSpeechDataset(train_encodings, train_labels)\n",
    "validation_dataset = HateSpeechDataset(validation_encodings, validation_labels)\n",
    "test_dataset = HateSpeechDataset(test_encodings, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BfTux3Xs7cvC"
   },
   "source": [
    "# Create the explanation methods\n",
    "\n",
    "Four methods are provided: \n",
    "\n",
    "1.   Averaging attention across all layers\n",
    "2.   Averaging attention only across last layer\n",
    "3.   LIME\n",
    "4.   Integrated Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jbQ8kGRuQcRf",
    "outputId": "5654017f-49bb-4023-f481-063943e646f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lime in /usr/local/lib/python3.7/dist-packages (0.2.0.1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from lime) (3.2.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from lime) (4.62.3)\n",
      "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.7/dist-packages (from lime) (1.0.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from lime) (1.4.1)\n",
      "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.7/dist-packages (from lime) (0.18.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from lime) (1.19.5)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime) (2021.11.2)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime) (7.1.2)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime) (1.2.0)\n",
      "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime) (2.4.1)\n",
      "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime) (2.6.3)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->lime) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->lime) (1.3.2)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->lime) (3.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->lime) (0.11.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->lime) (1.15.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->lime) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->lime) (3.0.0)\n",
      "Requirement already satisfied: transformers-interpret in /usr/local/lib/python3.7/dist-packages (0.5.2)\n",
      "Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from transformers-interpret) (4.15.0)\n",
      "Requirement already satisfied: captum>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from transformers-interpret) (0.4.1)\n",
      "Requirement already satisfied: torch>=1.2 in /usr/local/lib/python3.7/dist-packages (from captum>=0.3.1->transformers-interpret) (1.10.0+cu111)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from captum>=0.3.1->transformers-interpret) (1.19.5)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from captum>=0.3.1->transformers-interpret) (3.2.2)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.2->captum>=0.3.1->transformers-interpret) (3.10.0.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0->transformers-interpret) (0.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0->transformers-interpret) (6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0->transformers-interpret) (21.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0->transformers-interpret) (2019.12.20)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0->transformers-interpret) (0.0.47)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0->transformers-interpret) (0.10.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0->transformers-interpret) (2.23.0)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0->transformers-interpret) (4.10.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0->transformers-interpret) (4.62.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0->transformers-interpret) (3.4.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers>=3.0.0->transformers-interpret) (3.0.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers>=3.0.0->transformers-interpret) (3.7.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->captum>=0.3.1->transformers-interpret) (1.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->captum>=0.3.1->transformers-interpret) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->captum>=0.3.1->transformers-interpret) (0.11.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->captum>=0.3.1->transformers-interpret) (1.15.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=3.0.0->transformers-interpret) (2021.10.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=3.0.0->transformers-interpret) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=3.0.0->transformers-interpret) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=3.0.0->transformers-interpret) (3.0.4)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=3.0.0->transformers-interpret) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=3.0.0->transformers-interpret) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "#methods = ['attention_all', 'attention_last', 'IG']\n",
    "#Due to time constraints, we can run the rest of the techniques and then run LIME standalone\n",
    "#on the trained model, after loading it with output_attention=False\n",
    "methods = ['attention_all', 'attention_last', 'LIME' 'IG']\n",
    "\n",
    "\n",
    "#Import LIME\n",
    "! pip install lime\n",
    "import lime\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "\n",
    "#Import Integrated Gradients\n",
    "! pip install transformers-interpret\n",
    "from transformers_interpret import SequenceClassificationExplainer\n",
    "\n",
    "#Predictor function for LIME\n",
    "def predictor(texts):\n",
    "    encodings = tokenizer(list(texts), truncation=True, padding=True)\n",
    "    dataset = HateSpeechDataset(encodings, np.zeros(len(texts), dtype=int))\n",
    "    logits = model_predict(dataset)\n",
    "    probabilities = softmax(logits, axis = 1)\n",
    "    return probabilities\n",
    "\n",
    "#Base function for explanations\n",
    "def explainTexts(texts, method):\n",
    "    attributions = []\n",
    "    if method == 'LIME':\n",
    "        explainer = LimeTextExplainer(class_names=class_names, split_expression='\\s+', bow=False)\n",
    "        for i, test_phrase in enumerate(texts):\n",
    "            if i % 10 == 0:\n",
    "                print(\"Current sample:\", i)\n",
    "            exp = explainer.explain_instance(test_phrase, predictor, num_features=200, num_samples=2000)\n",
    "            explanation_dict = dict(list(exp.as_map().values())[0])\n",
    "            #Assign scores to bert tokens\n",
    "            scores = []\n",
    "            tokens = test_phrase.split(\" \")\n",
    "            for i in range(len(tokens)):\n",
    "                bert_tokens = tokenizer.encode(tokens[i],add_special_tokens = False)\n",
    "                bert_tokens = tokenizer.convert_ids_to_tokens(bert_tokens)\n",
    "                for j in range(len(bert_tokens)):\n",
    "                    scores.append((bert_tokens[j], explanation_dict[i]))\n",
    "            attributions.append(scores)\n",
    "    elif method == 'IG':\n",
    "        explainer = SequenceClassificationExplainer(model, tokenizer, custom_labels = class_names)\n",
    "        for test_phrase in texts:\n",
    "            scores = explainer(test_phrase)\n",
    "            #Delete CLS and SEP tokens\n",
    "            scores.pop(0)\n",
    "            scores.pop(-1)\n",
    "            attributions.append(scores)\n",
    "    else:\n",
    "        for text_id in range(len(texts)):\n",
    "            encodings = tokenizer(texts[text_id])\n",
    "            encodings['input_ids'] = np.reshape(encodings['input_ids'], (1,-1))\n",
    "            encodings['attention_mask'] = np.reshape(encodings['attention_mask'], (1,-1))\n",
    "            dataset = HateSpeechDataset(encodings, np.zeros(1, dtype=int))\n",
    "            attention_matrix = model_predict(dataset, return_attention=True)\n",
    "            if method == 'attention_all':\n",
    "                attention_matrix = attention_matrix.mean(axis=0).mean(axis=1).mean(axis=1)\n",
    "            elif method == 'attention_last':\n",
    "                attention_matrix = np.mean(attention_matrix[-1][:,:,0,:],axis=1)\n",
    "            scores = []\n",
    "            tokens = tokenizer.convert_ids_to_tokens(encodings['input_ids'][0])\n",
    "            for token_id in range(len(tokens)):\n",
    "                scores.append((tokens[token_id], attention_matrix[0][token_id]))\n",
    "            scores.pop(0)\n",
    "            scores.pop(-1)\n",
    "            attributions.append(scores)\n",
    "    return attributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mf0u2b7C8TH6"
   },
   "source": [
    "# Define performance and interpretability metrics\n",
    "\n",
    "For performance, we import accuracy, precision, recall and F1_score from sklearn, and define specificity and sensitivity.\n",
    "\n",
    "For interpretability, we define rationale based metrics, average nonzero-weights, robustness and faithfulness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y80X9YCQjYJH"
   },
   "outputs": [],
   "source": [
    "#Define performance metrics\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, precision_score, recall_score\n",
    "\n",
    "def specificity(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    if (tn+fp) > 0:\n",
    "        speci = tn/(tn+fp)\n",
    "        return speci\n",
    "    return 0\n",
    "\n",
    "def sensitivity(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    if (tp+fn) > 0:\n",
    "        sensi = tp/(tp+fn)\n",
    "        return sensi\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "18dm8335v9dA"
   },
   "outputs": [],
   "source": [
    "#Define ground truth based metrics\n",
    "#Code based on ERASER benchmark: https://github.com/jayded/eraserbenchmark/blob/master/rationale_benchmark/metrics.py\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "from sklearn.preprocessing import maxabs_scale\n",
    "\n",
    "#Extract only weights, discarding tokens in each tuple\n",
    "def extract_weights(attributions):\n",
    "    weights = []\n",
    "    for explanation in attributions:\n",
    "        weights.append([x[1] for x in explanation])\n",
    "    return weights\n",
    "\n",
    "#Scale weights to [-1, 1]\n",
    "def scale_weights(attributions):\n",
    "    for i in range(len(attributions)):\n",
    "        attributions[i] = maxabs_scale(np.reshape(attributions[i], (-1,1)))\n",
    "        attributions[i] = np.reshape(attributions[i], -1)\n",
    "    return attributions\n",
    "\n",
    "#Extract rationales with weight >= threshold\n",
    "def extract_hard_rationales(attributions, threshold):\n",
    "    attributions = scale_weights(attributions)\n",
    "    hard_rationales = []\n",
    "    for explanation in attributions:\n",
    "        rationale = []\n",
    "        for i in range(len(explanation)):\n",
    "            if explanation[i] >= threshold:\n",
    "                if rationale and rationale[-1][1] == i:\n",
    "                    rationale[-1] = (rationale[-1][0], rationale[-1][1] + 1)\n",
    "                else:\n",
    "                    rationale.append((i, i+1))\n",
    "        hard_rationales.append(rationale)\n",
    "    return hard_rationales\n",
    "\n",
    "#AUPRC metric for soft rationales\n",
    "def auprc(attributions, ground_truth):\n",
    "    aucs = []\n",
    "    for prediction, truth in zip(attributions, ground_truth):\n",
    "        precision, recall, _ = precision_recall_curve(truth, prediction)\n",
    "        aucs.append(auc(recall, precision))\n",
    "    return np.average(aucs) \n",
    "\n",
    "def calculate_macro_f1(true_positives, hard_rationales, hard_truth):\n",
    "    recall_per_sample = [true_positives[i] / len(truth) for i, truth in enumerate(hard_truth)]\n",
    "    precision_per_sample = [true_positives[i] / len(rationales) if len(rationales) > 0 else 0 for i, rationales in enumerate(hard_rationales)]\n",
    "    macro_recall = np.average(recall_per_sample)\n",
    "    macro_precision = np.average(precision_per_sample)\n",
    "    if macro_recall == 0 or macro_precision == 0:\n",
    "        return 0\n",
    "    f1 = 2 * (macro_precision * macro_recall) / (macro_precision + macro_recall)\n",
    "    return f1\n",
    "\n",
    "def IOU_F1(hard_rationales, hard_truth):\n",
    "    #Calculate best IOU(Intesection Over Union) for each rationale in each test sample\n",
    "    ious = []\n",
    "    for sample_id in range(len(hard_rationales)):\n",
    "        sample_ious = []\n",
    "        for rationale_id in range(len(hard_rationales[sample_id])):\n",
    "            rationale = hard_rationales[sample_id][rationale_id]\n",
    "            best_iou = 0.0\n",
    "            for truth in hard_truth[sample_id]:\n",
    "                num = len(set(range(rationale[0], rationale[1])) & set(range(truth[0], truth[1])))\n",
    "                denom = len(set(range(rationale[0], rationale[1])) | set(range(truth[0], truth[1])))\n",
    "                iou = 0 if denom == 0 else num / denom\n",
    "                if iou > best_iou:\n",
    "                    best_iou = iou\n",
    "            sample_ious.append(best_iou)\n",
    "        ious.append(sample_ious)\n",
    "\n",
    "    #Calculate macro F1 score\n",
    "    threshold = 0.5\n",
    "    true_positives = []\n",
    "    for sample in ious:\n",
    "        true_positives.append(sum(int(x >= threshold) for x in sample))\n",
    "    return calculate_macro_f1(true_positives, hard_rationales, hard_truth)\n",
    "\n",
    "def token_F1(hard_rationales, hard_truth):\n",
    "    #Turn eveything into token level\n",
    "    token_rationales = []\n",
    "    token_truth = []\n",
    "    for i in range(len(hard_rationales)):\n",
    "        temp = []\n",
    "        for rationale in hard_rationales[i]:\n",
    "            temp.extend(list(range(rationale[0], rationale[1])))\n",
    "        token_rationales.append(temp)\n",
    "    \n",
    "        temp = []\n",
    "        for truth in hard_truth[i]:\n",
    "            temp.extend(list(range(truth[0], truth[1])))\n",
    "        token_truth.append(temp)\n",
    "    #Calculate token F1 score\n",
    "    true_positives = [len(set(rationale) & set(truth)) for rationale, truth in zip(token_rationales, token_truth)]\n",
    "    return calculate_macro_f1(true_positives, token_rationales, token_truth)\n",
    "\n",
    "def hard_rationale_metrics(attributions, hard_truth, ground_truth_avg):\n",
    "    thresholds = [0.5, 0.33, ground_truth_avg]\n",
    "    dictionary = {}\n",
    "    for threshold in thresholds:\n",
    "        hard_rationales = extract_hard_rationales(attributions, threshold)\n",
    "        key1 = 'IOU F1 t=' + str(threshold)\n",
    "        key2 = 'Token F1 t=' + str(threshold)\n",
    "        dictionary.update({key1: IOU_F1(hard_rationales, hard_truth), key2: token_F1(hard_rationales, hard_truth)})\n",
    "    return dictionary\n",
    "\n",
    "def rationales_metrics(attributions, ground_truth, hard_truth, ground_truth_avg):\n",
    "    attributions = extract_weights(attributions)\n",
    "    #Get only hate speech samples\n",
    "    indexes = [index for index, truth in enumerate(ground_truth) if truth != 0]\n",
    "    attributions = [attributions[x] for x in indexes]\n",
    "    ground_truth = [ground_truth[x] for x in indexes]\n",
    "    hard_truth = [hard_truth[x] for x in indexes]\n",
    "    #Keep only positive weights, turn negative weights to 0\n",
    "    for attribution in attributions:\n",
    "        for i in range(len(attribution)):\n",
    "            if attribution[i] < 0:\n",
    "                attribution[i] = 0\n",
    "    metrics = {}\n",
    "    metrics['AUPRC'] = auprc(attributions, ground_truth)\n",
    "    metrics.update(hard_rationale_metrics(attributions, hard_truth, ground_truth_avg))\n",
    "  \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VEhoqX0gwHk5"
   },
   "outputs": [],
   "source": [
    "#Define functional based metrics\n",
    "\n",
    "def nonzero_weights(attributions):\n",
    "    threshold = 0.001\n",
    "    attributions = extract_weights(attributions)\n",
    "    attributions = scale_weights(attributions)\n",
    "    nonzero_weights = 0\n",
    "    for explanation in attributions:\n",
    "        abs_weights = np.abs(explanation)\n",
    "        nonzero_weights += (abs_weights > threshold).sum()\n",
    "    return nonzero_weights / len(attributions)\n",
    "\n",
    "def robustness(attributions, method):\n",
    "    initial_weights = extract_weights(attributions)\n",
    "\n",
    "    #Add UNK token to the end of each test document\n",
    "    tweaked_texts = []\n",
    "    for i in range(len(test_texts)):\n",
    "        tweaked_texts.append(test_texts[i] + ' ðŸ˜')\n",
    "\n",
    "    #Get new weights\n",
    "    new_weights = explainTexts(tweaked_texts, method)\n",
    "    new_weights = extract_weights(new_weights)\n",
    "\n",
    "    #Scale weights to [-1, 1]\n",
    "    initial_weights = scale_weights(initial_weights)\n",
    "    new_weights = scale_weights(new_weights)\n",
    "\n",
    "    #Pad initial weights for UNK token\n",
    "    for i in range(len(initial_weights)):\n",
    "        while len(new_weights[i]) > len(initial_weights[i]):\n",
    "            initial_weights[i] = np.append(initial_weights[i], 0.0)\n",
    "\n",
    "    differences = []\n",
    "    for i in range(len(initial_weights)):\n",
    "        diff = np.sum(np.absolute(np.subtract(new_weights[i], initial_weights[i])))\n",
    "        differences.append(diff)\n",
    "    return np.average(differences)\n",
    "\n",
    "def faithfulness(attributions, method):\n",
    "    #Get original probabilities\n",
    "    logits = model_predict(test_dataset)\n",
    "    original_probabilities = softmax(logits, axis = 1)\n",
    "\n",
    "    #Create new attention masks to ignore most important tokens for each test document\n",
    "    tweaked_encodings = tokenizer(list(test_texts), truncation=True, padding=True)\n",
    "    attention_masks = []\n",
    "    weights = extract_weights(attributions)\n",
    "    for i in range(len(weights)):\n",
    "        explanation = weights[i]\n",
    "        max_weight = max(explanation)\n",
    "        max_indexes = [index+1 for index, value in enumerate(explanation) if value == max_weight]\n",
    "        original_attention_mask = tweaked_encodings['attention_mask'][i]\n",
    "        for index in max_indexes:\n",
    "            original_attention_mask[index] = 0\n",
    "\n",
    "    tweaked_dataset = HateSpeechDataset(tweaked_encodings, test_labels)\n",
    "\n",
    "    #Get tweaked probabilities\n",
    "    logits = model_predict(tweaked_dataset)\n",
    "    tweaked_probabilities = softmax(logits, axis = 1)\n",
    "\n",
    "    #Get predicted class of each original prediction\n",
    "    y_preds = []\n",
    "    for i in original_probabilities:\n",
    "        y_preds.append(np.argmax(i))\n",
    "\n",
    "    #Get probability of predicted class for each sample\n",
    "    original_y = original_probabilities[np.arange(len(original_probabilities)), y_preds]\n",
    "    tweaked_y = tweaked_probabilities[np.arange(len(tweaked_probabilities)), y_preds]\n",
    "  \n",
    "    return np.average(original_y - tweaked_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dVzmaB9J8v7m"
   },
   "source": [
    "# Evaluate (Distil)BERT \n",
    "\n",
    "We now train the (Distil)Bert model, save its weights, and then run the performance and interpretability evaluation metrics on the test dataset and output the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 420,
     "referenced_widgets": [
      "e690521da25d413fa597af14522f04aa",
      "30f56509262b43df9656278d217bf5a9",
      "a039c898fcb342b293ce6eaa4f44e838",
      "f0715cce321b4de5997f4c292e81bde4",
      "2dbad3091b8845179febedc3dbb76ba7",
      "f49bc1bf30f2489795bd98dbadf36521",
      "02fe8e099f5f4a7282a286279f673a83",
      "545a7c933b0146048e5eb6f996925583",
      "dcae03595fb745e39ef0898ece900a59",
      "754541e1626c46079853037a4963f3e7",
      "4d27623ad797484eb8a80d3e99e2e30b"
     ]
    },
    "id": "fHf2zXLmxc_R",
    "outputId": "0356e522-57af-4a62-e363-6dbddb9fb3b0"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e690521da25d413fa597af14522f04aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14436' max='14436' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14436/14436 42:32, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.542900</td>\n",
       "      <td>0.410997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.436900</td>\n",
       "      <td>0.399812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.300300</td>\n",
       "      <td>0.502414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.212400</td>\n",
       "      <td>0.671766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.152500</td>\n",
       "      <td>0.629400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.097100</td>\n",
       "      <td>0.663480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=14436, training_loss=0.2903610202010301, metrics={'train_runtime': 2553.7235, 'train_samples_per_second': 22.612, 'train_steps_per_second': 5.653, 'total_flos': 5311644874505280.0, 'train_loss': 0.2903610202010301, 'epoch': 6.0})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Run a prediction on a dataset and return the logits or the attention matrix\n",
    "def model_predict(dataset, return_attention=False):\n",
    "    if return_attention:\n",
    "        predictions = trainer.predict(dataset).predictions\n",
    "        attention_matrix = predictions[1]\n",
    "        attention_matrix = np.array(list(attention_matrix))\n",
    "        return attention_matrix\n",
    "    else:\n",
    "        all_logits = []\n",
    "        dataloader = torch.utils.data.DataLoader(dataset, batch_size=100) #Change batch_size accordingly\n",
    "        for _, batch in enumerate(dataloader):\n",
    "            batch_dataset = HateSpeechDataset({key:batch[key] for key in ['input_ids','attention_mask']}, batch['labels'])\n",
    "            predictions = trainer.predict(batch_dataset).predictions\n",
    "            logits = predictions[0]\n",
    "            all_logits.extend(logits)\n",
    "        return np.array(all_logits)\n",
    "\n",
    "if model_used == 'Bert':\n",
    "    model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", output_attentions=True)\n",
    "else:\n",
    "    model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", output_attentions=True)\n",
    "\n",
    "#Train model\n",
    "trainer = Trainer(\n",
    "            model=model,                         # the instantiated Transformers model to be trained\n",
    "            args=training_args,                  # training arguments\n",
    "            train_dataset=train_dataset,         # training dataset\n",
    "            eval_dataset=validation_dataset      # evaluation dataset\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z6mVI_tlZgiA"
   },
   "outputs": [],
   "source": [
    "#Save model\n",
    "model.save_pretrained(\"bert_model/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "id": "uSqKGehjkHw4",
    "outputId": "7808373c-aee2-4066-c1d5-e4dbda01552f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='110' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:26]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "logits = model_predict(test_dataset)\n",
    "\n",
    "#Get predicted labels\n",
    "y_preds = []\n",
    "for i in logits:\n",
    "    y_preds.append(np.argmax(i))\n",
    "\n",
    "#Compute performance metrics\n",
    "name = model_used\n",
    "performance_scores = {name:{}}\n",
    "performance_scores[name]['F1'] = f1_score(test_labels, y_preds, average='macro')\n",
    "performance_scores[name]['Precision'] = precision_score(test_labels, y_preds, average='macro')\n",
    "performance_scores[name]['Recall'] = recall_score(test_labels, y_preds, average='macro')\n",
    "performance_scores[name]['Accuracy'] = accuracy_score(test_labels, y_preds)\n",
    "performance_scores[name]['Specificity'] = specificity(test_labels, y_preds)\n",
    "performance_scores[name]['Sensitivity'] = sensitivity(test_labels, y_preds)\n",
    "\n",
    "#Print metrics\n",
    "pd.set_option('display.max_columns', None)\n",
    "df = pd.DataFrame(performance_scores).T\n",
    "df.to_csv('bert_performance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 213
    },
    "id": "X7lheZEakQxF",
    "outputId": "933cdd4a-b076-40cc-eca4-5953863d2d3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current method:  attention_all\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5610' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 02:14]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current method:  attention_last\n",
      "Current method:  IG\n",
      "attention_all\n",
      "[('user', 0.018255835), ('china', 0.01690993), ('##man', 0.026505345), ('satan', 0.045628767), ('##ist', 0.022424813), ('lee', 0.01888416), ('hs', 0.017990084), ('##ien', 0.016633952), ('lo', 0.013514362), ('##ong', 0.019136101), ('malaysian', 0.042037945), ('criminals', 0.039498292), ('have', 0.02232611), ('been', 0.02109984), ('gossip', 0.02260688), ('##ing', 0.017562084), ('false', 0.021904739), ('information', 0.019355634), ('to', 0.020091066), ('the', 0.018966367), ('nt', 0.01700514), ('##uc', 0.016089827), ('supermarket', 0.031740677), ('se', 0.014989028), ('##mba', 0.018736701), ('##wang', 0.01750711), ('mart', 0.016503518), ('staff', 0.021204531), ('since', 0.020392813), ('mid', 0.015896866), ('number', 0.018105108), ('swift', 0.0152528975), ('discoveries', 0.021038383), ('if', 0.019939095), ('questioned', 0.02578365)]\n",
      "attention_last\n",
      "[('user', 0.02724658), ('china', 0.027133947), ('##man', 0.027255243), ('satan', 0.027295297), ('##ist', 0.027219353), ('lee', 0.027047636), ('hs', 0.027020894), ('##ien', 0.027115673), ('lo', 0.027101627), ('##ong', 0.027221588), ('malaysian', 0.027345045), ('criminals', 0.027264409), ('have', 0.026956536), ('been', 0.026903348), ('gossip', 0.026985511), ('##ing', 0.02677252), ('false', 0.027039783), ('information', 0.026910039), ('to', 0.026806468), ('the', 0.026929453), ('nt', 0.026976846), ('##uc', 0.027310064), ('supermarket', 0.027171202), ('se', 0.027025804), ('##mba', 0.027113639), ('##wang', 0.027161226), ('mart', 0.027250564), ('staff', 0.027050765), ('since', 0.026461488), ('mid', 0.026590519), ('number', 0.026475705), ('swift', 0.026484882), ('discoveries', 0.026544863), ('if', 0.026654005), ('questioned', 0.026988568)]\n",
      "IG\n",
      "[('user', 0.3390935813616494), ('china', 0.13851332489341095), ('##man', 0.09273404347369839), ('satan', 0.42670122384176146), ('##ist', 0.47395565751471114), ('lee', -0.11299459453309668), ('hs', 0.060273488403500254), ('##ien', 0.10487130536451093), ('lo', -0.1263009518302877), ('##ong', -0.052444974178062854), ('malaysian', 0.022284661313405753), ('criminals', 0.25832532034006267), ('have', 0.05277869665684337), ('been', -0.058968545151997426), ('gossip', -0.07856202869102237), ('##ing', -0.04771008228400554), ('false', 0.07022894455583144), ('information', 0.33287332911469525), ('to', 0.03263944989990886), ('the', -0.04377999143669468), ('nt', 0.21351881782002), ('##uc', 0.052002698785008364), ('supermarket', 0.09907404524253867), ('se', 0.12552311445145262), ('##mba', -0.14402276529813896), ('##wang', -0.07268186998046038), ('mart', 0.001302736386034242), ('staff', 0.2590160148093286), ('since', 0.08127193730713943), ('mid', 0.007554352581406753), ('number', 0.03158295303277135), ('swift', 0.050716359508511444), ('discoveries', 0.0887239332084261), ('if', 0.13282442215137585), ('questioned', -0.032155396654216836)]\n"
     ]
    }
   ],
   "source": [
    "attributions = {}\n",
    "\n",
    "#Compute explanation vectors for test dataset\n",
    "for method in methods:\n",
    "    print(\"Current method: \",method)\n",
    "    attributions[method] = explainTexts(test_texts, method)\n",
    "\n",
    "#Print an example\n",
    "for method in attributions:\n",
    "    print(method)\n",
    "    print(attributions[method][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "id": "GglNYgT0kZyD",
    "outputId": "22917b09-f590-4c46-aecc-bc708bdb6195"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current method:  attention_all\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11770' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 34:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current method:  attention_last\n",
      "Current method:  IG\n"
     ]
    }
   ],
   "source": [
    "#Initialize interpretability scores\n",
    "interpretability_scores = {}\n",
    "for method in methods:\n",
    "    interpretability_scores.setdefault(method, {})\n",
    "\n",
    "#Compute interpretability metrics\n",
    "for method in methods:\n",
    "    print(\"Current method: \",method)\n",
    "    interpretability_scores[method].update(rationales_metrics(attributions[method], ground_truth, hard_truth, ground_truth_avg))\n",
    "    interpretability_scores[method]['average_nonzero_weights'] = nonzero_weights(attributions[method])\n",
    "    interpretability_scores[method]['robustness'] = robustness(attributions[method], method)\n",
    "    interpretability_scores[method]['faithfulness'] = faithfulness(attributions[method], method)\n",
    "\n",
    "#Print metrics\n",
    "df = pd.DataFrame(interpretability_scores).T\n",
    "df.to_csv('bert_interpretations.csv')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "HateXplain Evaluation with dataloader.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "02fe8e099f5f4a7282a286279f673a83": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "07d772f2e9274368bfc6c4ceca5d1fa3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "081ea3173d754ab0a0e608bea79b7254": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1039074a09fd4549b48d6824f2216cdd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "112051f8f4144c12a84d30ac1037b394": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1e79b09b5d684e3a8dc288cb65f87679": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "202e1116a5de48e59c61022fc7a78e8e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7cf13684d5044c0c945854a912049799",
       "IPY_MODEL_5843af756e3c42689d2c34d2abc91e07",
       "IPY_MODEL_cdcffb5e6b3c4db7a8a425fbf510ca5f"
      ],
      "layout": "IPY_MODEL_c3f0caf43cf84fa4ad308f413c53a4b6"
     }
    },
    "21c88403bea94e088495fad3cc92d344": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bc2e2eefc59846278f3c59478bb74ebb",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_081ea3173d754ab0a0e608bea79b7254",
      "value": " 455k/455k [00:00&lt;00:00, 808kB/s]"
     }
    },
    "2dbad3091b8845179febedc3dbb76ba7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4d27623ad797484eb8a80d3e99e2e30b",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_754541e1626c46079853037a4963f3e7",
      "value": " 420M/420M [00:10&lt;00:00, 27.4MB/s]"
     }
    },
    "2de454f08ef34be390d82656600abf3a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1039074a09fd4549b48d6824f2216cdd",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_b4935b7c13ee4759a56794030e76646a",
      "value": "Downloading: 100%"
     }
    },
    "30f56509262b43df9656278d217bf5a9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "346dbcafd2634e4d87b615c4835e9ef0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "35cbf5c213574362b3e05889e30be477": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "42519b4bd04d49ef92ce30e72d4c798f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4d27623ad797484eb8a80d3e99e2e30b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "53a3247730424b7394c906269b9000f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "545a7c933b0146048e5eb6f996925583": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "571ebcb725c1411d97e087d93a63e1b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_efc2b0c4bbc04c12b5881d047ebced5d",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_67c43adb9c724781a0b3dda6eec8151e",
      "value": " 226k/226k [00:00&lt;00:00, 894kB/s]"
     }
    },
    "5843af756e3c42689d2c34d2abc91e07": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a1a9debac2644c4f88456da2c97d6e7e",
      "max": 28,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d089ba5080784d4199af642031386700",
      "value": 28
     }
    },
    "67c43adb9c724781a0b3dda6eec8151e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "70fda8df889c4155a1ce749fb31cf067": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cc746aa48ee243159c766a8fc0b00e8d",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_d3f17de082f54c42823ff7a82076ff6a",
      "value": "Downloading: 100%"
     }
    },
    "754541e1626c46079853037a4963f3e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7cf13684d5044c0c945854a912049799": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_92ad4986898e43bca22787e94d34deac",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_53a3247730424b7394c906269b9000f2",
      "value": "Downloading: 100%"
     }
    },
    "8a1b581289bc494c8eb6c43160779993": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8d6020b7d5574a559af636b82b72ba6e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8a1b581289bc494c8eb6c43160779993",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_07d772f2e9274368bfc6c4ceca5d1fa3",
      "value": 231508
     }
    },
    "8e26e633273a4fafa1ef90b0f8831c1a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_346dbcafd2634e4d87b615c4835e9ef0",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_35cbf5c213574362b3e05889e30be477",
      "value": " 570/570 [00:00&lt;00:00, 17.6kB/s]"
     }
    },
    "8fe218c1b6d8433b8dee577d8c430998": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ffe2859dba7e4dcabea2ece56947d094",
      "max": 570,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d61b5b8630524d3a8a7f19f2cceb59de",
      "value": 570
     }
    },
    "92ad4986898e43bca22787e94d34deac": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "96b49575251948eb862dffb96266a0eb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2de454f08ef34be390d82656600abf3a",
       "IPY_MODEL_8fe218c1b6d8433b8dee577d8c430998",
       "IPY_MODEL_8e26e633273a4fafa1ef90b0f8831c1a"
      ],
      "layout": "IPY_MODEL_fcdba66e4a7748f982e677ac222d98fc"
     }
    },
    "9d115699d3124cf293c97a3b041327e0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9fea71a96a19486cb174bf6efc3c836e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9d115699d3124cf293c97a3b041327e0",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_112051f8f4144c12a84d30ac1037b394",
      "value": "Downloading: 100%"
     }
    },
    "a039c898fcb342b293ce6eaa4f44e838": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_02fe8e099f5f4a7282a286279f673a83",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_f49bc1bf30f2489795bd98dbadf36521",
      "value": "Downloading: 100%"
     }
    },
    "a1a9debac2644c4f88456da2c97d6e7e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a3dbe12b767d4203b703cc1c4b15024f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a3f886dbd6c24292bd38d31e5954f11f",
      "max": 466062,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1e79b09b5d684e3a8dc288cb65f87679",
      "value": 466062
     }
    },
    "a3f886dbd6c24292bd38d31e5954f11f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a68f54b7107c49408b8b391b4b824cac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b4935b7c13ee4759a56794030e76646a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bc2e2eefc59846278f3c59478bb74ebb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bd2a3b1ae6294123b9bedf3f54e21817": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9fea71a96a19486cb174bf6efc3c836e",
       "IPY_MODEL_8d6020b7d5574a559af636b82b72ba6e",
       "IPY_MODEL_571ebcb725c1411d97e087d93a63e1b2"
      ],
      "layout": "IPY_MODEL_c9883f3149e44674b38cb5702c20f9ac"
     }
    },
    "c3f0caf43cf84fa4ad308f413c53a4b6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c9883f3149e44674b38cb5702c20f9ac": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cc746aa48ee243159c766a8fc0b00e8d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cdcffb5e6b3c4db7a8a425fbf510ca5f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ff2a95e5455744f3b7f6d082788bdf03",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_a68f54b7107c49408b8b391b4b824cac",
      "value": " 28.0/28.0 [00:00&lt;00:00, 853B/s]"
     }
    },
    "d089ba5080784d4199af642031386700": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d3f17de082f54c42823ff7a82076ff6a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d61b5b8630524d3a8a7f19f2cceb59de": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d676303de9fb4c528a178031afcbb4de": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_70fda8df889c4155a1ce749fb31cf067",
       "IPY_MODEL_a3dbe12b767d4203b703cc1c4b15024f",
       "IPY_MODEL_21c88403bea94e088495fad3cc92d344"
      ],
      "layout": "IPY_MODEL_42519b4bd04d49ef92ce30e72d4c798f"
     }
    },
    "dcae03595fb745e39ef0898ece900a59": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e690521da25d413fa597af14522f04aa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a039c898fcb342b293ce6eaa4f44e838",
       "IPY_MODEL_f0715cce321b4de5997f4c292e81bde4",
       "IPY_MODEL_2dbad3091b8845179febedc3dbb76ba7"
      ],
      "layout": "IPY_MODEL_30f56509262b43df9656278d217bf5a9"
     }
    },
    "efc2b0c4bbc04c12b5881d047ebced5d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f0715cce321b4de5997f4c292e81bde4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dcae03595fb745e39ef0898ece900a59",
      "max": 440473133,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_545a7c933b0146048e5eb6f996925583",
      "value": 440473133
     }
    },
    "f49bc1bf30f2489795bd98dbadf36521": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fcdba66e4a7748f982e677ac222d98fc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ff2a95e5455744f3b7f6d082788bdf03": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ffe2859dba7e4dcabea2ece56947d094": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
